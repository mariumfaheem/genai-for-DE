{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Data Engineering Code with Gen AI\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Examples\n",
    "3. References and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Generative AI can be utilized in various ways for writing data engineering code, specifically for creating efficient and accurate data pipelines:\n",
    "\n",
    "1. Code Generation: Automatically generating data engineering scripts based on high-level descriptions of tasks.\n",
    "2. Optimization: Improving existing data engineering code based on performance feedback and best practices.\n",
    "3. Schema Understanding: Interpreting data schemas to inform code generation and optimization.\n",
    "4. Error Detection and Correction: Identifying and fixing errors in data engineering code through automated analysis.\n",
    "5. Code Translation: Converting code between different programming languages and frameworks used in data engineering.\n",
    "6. Complex Workflow Creation: Generating complex data workflows and pipelines based on user requirements.\n",
    "7. Result Interpretation: Translating data processing results into human-readable reports and summaries.\n",
    "8. Data Quality Checks: Generating code for validating data quality and consistency in pipelines.\n",
    "9. Documentation Generation: Creating detailed documentation for data engineering code and workflows automatically.\n",
    "\n",
    "Using Gen AI for this task offers several benefits:\n",
    "\n",
    "- Increased productivity and efficiency for data engineers\n",
    "- Faster development and deployment of data pipelines\n",
    "- Reduced errors in code\n",
    "- Improved maintainability and readability of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import sklearn\n",
    "\n",
    "# Set up OpenAI API key\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "def clean(dict_variable):\n",
    "    return next(iter(dict_variable.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 1: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Loan_Applications_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaNs by column without using specific functions\n",
    "nan_counts = {}\n",
    "for column in df.columns:\n",
    "    nan_count = 0\n",
    "    for value in df[column]:\n",
    "        if value != value:  # NaN values are not equal to themselves\n",
    "            nan_count += 1\n",
    "    nan_counts[column] = nan_count\n",
    "\n",
    "# Print the results\n",
    "for column, count in nan_counts.items():\n",
    "    print(f\"{column}: {count} NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code from ChatGPT here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df = knn_impute(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaNs by column without using specific functions\n",
    "nan_counts = {}\n",
    "for column in df.columns:\n",
    "    nan_count = 0\n",
    "    for value in df[column]:\n",
    "        if value != value:  # NaN values are not equal to themselves\n",
    "            nan_count += 1\n",
    "    nan_counts[column] = nan_count\n",
    "\n",
    "# Print the results\n",
    "for column, count in nan_counts.items():\n",
    "    print(f\"{column}: {count} NaNs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 2: Data modeling and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model(df, 'Approved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 3: Add code documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without documentation\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "iso = IsolationForest(contamination=0.05)\n",
    "outliers = iso.fit_predict(df_imputed)\n",
    "df_cleaned = df_imputed[outliers != -1]\n",
    "X = df_cleaned.drop(columns='target')\n",
    "y = df_cleaned['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "results = {\n",
    "    'mean_squared_error': mse,\n",
    "    'coefficients': model.coef_,\n",
    "    'intercept': model.intercept_,\n",
    "    'predictions': y_pred.tolist(),\n",
    "    'actual': y_test.tolist()\n",
    "}\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 4: Custom schema based on requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promotion Name\n",
    "# Return Date\n",
    "# Customer Contact Information\n",
    "# Reorder Level\n",
    "# Cost of Goods Sold (COGS)\n",
    "# Employee ID\n",
    "# Store Manager\n",
    "# Gross Profit\n",
    "# Shelf Location\n",
    "# Return Reason\n",
    "# Customer ID\n",
    "# Price Change Date\n",
    "# Order Quantity\n",
    "# Sales Price\n",
    "# Cost Price\n",
    "# Customer Loyalty Points\n",
    "# Order Date\n",
    "# Supplier Name\n",
    "# Store Location\n",
    "# Return ID\n",
    "# Promotion Effectiveness\n",
    "# Promotion Start Date\n",
    "# Promotion End Date\n",
    "# Feedback ID\n",
    "# Supplier ID\n",
    "# Customer Name\n",
    "# Promotion ID\n",
    "# Sales Performance\n",
    "# Employee Name\n",
    "# Product Category\n",
    "# Employee Role\n",
    "# Customer Feedback\n",
    "# Total Sales Amount\n",
    "# Supplier Contact Information\n",
    "# Stock Level\n",
    "# Refund Amount\n",
    "# Selling Price\n",
    "# Sales Information\n",
    "# Compliance Check Date\n",
    "# SKU (Stock Keeping Unit)\n",
    "# Order Status\n",
    "# Store ID\n",
    "# Net Profit\n",
    "# Energy Consumption\n",
    "# Reorder Quantity\n",
    "# UPC (Universal Product Code)\n",
    "# Maintenance Schedule\n",
    "# Store Hours\n",
    "# Brand\n",
    "# Description\n",
    "# Product Name\n",
    "# Revenue\n",
    "# Waste Management\n",
    "# Order ID\n",
    "# Compliance Status\n",
    "# Transaction ID\n",
    "# Feedback Date\n",
    "# Expiry Date\n",
    "# Peak Hours\n",
    "# Expenses\n",
    "# Season End Date\n",
    "# Supply Lead Time\n",
    "# Product ID\n",
    "# Work Schedule\n",
    "# Supplier\n",
    "# Customer Feedback\n",
    "# Return Reason\n",
    "# Feedback Comments\n",
    "# Employee ID\n",
    "# Return Reason\n",
    "# Product Name\n",
    "# Refund Amount\n",
    "# Supplier Contact Information\n",
    "# Reorder Quantity\n",
    "# Stock Level\n",
    "# Reorder Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 5: Origin of column based on schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbml_code = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'write sql code to get the top 5 customers by sales'\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a SQL and DBML expert\"},\n",
    "        {\"role\": \"user\", \"content\": \"Answer the following question {}. DBML: {}\".format(question, dbml_code)}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 2. Example 6: Data movement between two systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code that will move data in a table stored in a MySQL SQL server to a MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "## 3. References and Further Reading\n",
    "\n",
    "1. OpenAI API Documentation: https://platform.openai.com/docs/\n",
    "2. \"Natural Language Processing for Data Engineers\" by Smith et al. (2023): https://arxiv.org/abs/2301.04567\n",
    "3. \"Using AI to Automate Data Engineering Tasks\" by Johnson et al. (2022): https://arxiv.org/abs/2210.09876\n",
    "4. \"Advanced Data Engineering with Machine Learning\" by Martin Brown and Lisa White\n",
    "5. \"The Data Engineering Handbook\" by Joe Reis and Matt Housley"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
