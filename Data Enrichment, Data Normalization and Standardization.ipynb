{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Enrichment, Data Normalization and Standardization\n",
    "\n",
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Examples\n",
    "3. References and Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Set up OpenAI API key\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "def clean(dict_variable):\n",
    "    return next(iter(dict_variable.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 1: Analyzing and Classifying News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample news article\n",
    "news_article = \"\"\"\n",
    "[ARTICLE 1]\n",
    "The stock market saw significant gains today as tech companies reported strong quarterly earnings. \n",
    "Apple, Microsoft, and Amazon all beat analyst expectations, driving the NASDAQ to new highs. \n",
    "Meanwhile, concerns about inflation have eased slightly following the Federal Reserve's latest statement.\n",
    "\n",
    "[ARTICLE 2]\n",
    "Simone Biles fought through pain in her calf on Sunday to post an impressive all-around score and display \n",
    "the qualities which have made one of the greatest gymnasts of all time on her return to the Olympics.\n",
    "\"\"\"\n",
    "\n",
    "# Analyze and classify the article\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes and classifies news articles.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze this news article and classify it into one of these categories: Technology, Sports, Other. Output in JSON form: {news_article}\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how Gen AI can analyze a news article, classify it into categories, and provide a summary. This is useful for data engineers working with large collections of news articles, helping to organize and extract key information efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 1: Filling Missing Text Data (Text Data Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with missing text data\n",
    "data = {\n",
    "    'Title': ['The Great Gatsby', 'To Kill a Mockingbird', '1984', 'Pride and Prejudice'],\n",
    "    'Author': ['F. Scott Fitzgerald', 'Harper Lee', 'George Orwell', None],\n",
    "    'Genre': ['Novel', 'Fiction', 'Dystopian', 'Romance']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict missing author\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Author'] is None:\n",
    "        prompt = 'Who is the author of this book? Return only the answer. {}'.format(row['Title'])\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        df.at[index, 'Author'] = response.choices[0].message.content\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with missing text data\n",
    "data = {\n",
    "    'Book Title': [None, 'To Kill a Mockingbird', '1984', 'Pride and Prejudice'],\n",
    "    'Author': ['F. Scott Fitzgerald', 'Harper Lee', 'George Orwell', None],\n",
    "    'Genre': ['Novel', 'Fiction', 'Dystopian', 'Romance']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for col in df.columns:\n",
    "        if row[col] is None:\n",
    "            prompt = 'Given this information: {}. What is the {}? Return only the answer'.format([{col_loop: row[col_loop]} for col_loop in df.columns if col_loop != col], col)\n",
    "            print(prompt)\n",
    "    \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            df.at[index, col] = response.choices[0].message.content\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example2'></a>\n",
    "## 2. Example 2: Filling Missing Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with missing numerical data\n",
    "data_num = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Price': [10.99, np.nan, 15.50, 8.75, np.nan],\n",
    "    'Quantity': [100, 150, np.nan, 200, 175]\n",
    "})\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill missing numerical data\n",
    "def fill_missing_numerical(row):\n",
    "    if pd.isna(row['Price']) or pd.isna(row['Quantity']):\n",
    "        prompt = f\"Predict the missing values for this product: Product: {row['Product']}, Price: {row['Price']}, Quantity: {row['Quantity']}. Consider market trends and product characteristics. Output in JSON form.\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        if pd.isna(row['Price']):\n",
    "            row['Price'] = float(result.get('Price', row['Price']))\n",
    "        if pd.isna(row['Quantity']):\n",
    "            row['Quantity'] = int(result.get('Quantity', row['Quantity']))\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "data_num_filled = data_num.apply(fill_missing_numerical, axis=1)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_num_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset with missing numerical data\n",
    "data_num = pd.DataFrame({\n",
    "    'Product': ['iPhone 12', 'iPhone 11', 'iPhone X', 'iPhone 7', 'iPhone 14'],\n",
    "    'Price': [599, 499, 399, 299, np.nan],\n",
    "    'Number of days since release': [1374, 1773, np.nan, 2872, 681]\n",
    "})\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill missing numerical data\n",
    "def fill_missing_numerical(row):\n",
    "    if pd.isna(row['Price']) or pd.isna(row['Number of days since release']):\n",
    "        prompt = f\"Predict the missing values for this product: Product: {row['Product']}, Price: {row['Price']}, Quantity: {row['Number of days since release']}. Consider market trends and product characteristics. You must provide a value. Only return the value, nothing else\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        \n",
    "        if pd.isna(row['Price']):\n",
    "            row['Price'] = result\n",
    "        if pd.isna(row['Number of days since release']):\n",
    "            row['Number of days since release'] = result\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "data_num_filled = data_num.apply(fill_missing_numerical, axis=1)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_num_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example3'></a>\n",
    "## 2. Example 3: Filling Missing Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample time series dataset with missing values\n",
    "dates = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
    "data_ts = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Temperature': [20, 22, np.nan, 19, 18, np.nan, 23, 25, 24, np.nan]\n",
    "})\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill missing time series data\n",
    "def fill_missing_timeseries(data):\n",
    "    context = data.to_json(orient='records', date_format='iso')\n",
    "    prompt = f\"Fill in the missing temperature values in this time series data. Consider trends and patterns. Data: {context}. Output in JSON form.\"\n",
    "\n",
    "    print(prompt)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    filled_data = pd.DataFrame(clean(result))\n",
    "    filled_data['Date'] = pd.to_datetime(filled_data['Date'])\n",
    "    \n",
    "    return filled_data\n",
    "\n",
    "# Apply the function to the dataset\n",
    "data_ts_filled = fill_missing_timeseries(data_ts)\n",
    "\n",
    "print(\"Dataset with filled missing values:\")\n",
    "print(data_ts_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_ts['Date'], data_ts['Temperature'], marker='o')\n",
    "plt.title('Temperature Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_ts_filled['Date'], data_ts_filled['Temperature'], marker='o')\n",
    "plt.title('Temperature Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 4: Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with mixed data types\n",
    "data = {\n",
    "    'ID': ['001', '002', '003', '00006'],\n",
    "    'Value': ['10.5', '15', 'twenty', 'thirty-one'],\n",
    "    'Date': ['2023-01-01', '01/15/2023', 'March 1, 2023', 'Dec 4,, \\'94']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gen AI to convert data types\n",
    "prompt = f\"Convert the following data to appropriate data types. ID should be integer, Value should be float (convert 'twenty' to 20.0), and Date should be in ISO format (YYYY-MM-DD). Output in JSON form:\\n{df.to_json()}\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "converted_data = json.loads(response.choices[0].message.content)\n",
    "print(\"\\nConverted data:\")\n",
    "print(json.dumps(converted_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with converted values\n",
    "df_converted = pd.DataFrame(converted_data)\n",
    "df_converted['ID'] = df_converted['ID'].astype(int)\n",
    "df_converted['Value'] = df_converted['Value'].astype(float)\n",
    "df_converted['Date'] = pd.to_datetime(df_converted['Date'])\n",
    "print(\"\\nFinal converted DataFrame:\")\n",
    "print(df_converted)\n",
    "print(\"\\nData types:\")\n",
    "print(df_converted.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [\n",
    "    \"123 Main St, Apt 4, New York, NY 10001\",\n",
    "    \"60601 456 Elm Avenue, Chicago\",\n",
    "    \"Los Angeles 789 Oak Rd Suite 100 Cali 90001\"\n",
    "]\n",
    "\n",
    "prompt = f\"Normalize these addresses to a standard format: {addresses}. Output in JSON form with keys: street, city, state, zip.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clean(json.loads(response.choices[0].message.content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example2'></a>\n",
    "## 2. Example 5: Normalizing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with inconsistent text formatting\n",
    "data = {\n",
    "    'descriptions': ['RED apple', 'Green BANANA', 'yellow Lemon', 'ORANGE orange']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gen AI to normalize text data\n",
    "prompt = f\"Normalize these fruit descriptions by capitalizing only the first letter of each word: {df['descriptions'].tolist()}. Output in JSON form\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "normalized_descriptions = json.loads(response.choices[0].message.content)\n",
    "print(\"Normalized descriptions:\")\n",
    "print(clean(normalized_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrame with normalized descriptions\n",
    "df['normalized_descriptions'] = clean(normalized_descriptions)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example3'></a>\n",
    "## 2. Example 6: Standardizing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with inconsistent categorical values\n",
    "data = {\n",
    "    'categories': ['IT', 'Information Technology', 'Tech', 'I.T.', 'Information Tech', 'Cyber', 'Cyberscryity', 'Cybersecurity']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gen AI to standardize categorical data\n",
    "prompt = f\"Standardize these category names to a single consistent format (either 'IT' or 'Cybersecurity'): {df['categories'].tolist()}. Output in JSON form\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "standardized_categories = json.loads(response.choices[0].message.content)\n",
    "print(\"Standardized categories:\")\n",
    "print(standardized_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrame with standardized categories\n",
    "df['standardized_categories'] = clean(standardized_categories)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 7: Standardizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample product names\n",
    "product_names = [\n",
    "    \"iPhone 12 Pro Max 256GB\",\n",
    "    \"Apple iphone 12 pro max (256 gb)\",\n",
    "    \"12 Pro Max iPhone - 256GB\"\n",
    "]\n",
    "\n",
    "# Function to standardize product name\n",
    "def standardize_product_name(name):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a product name standardization assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Standardize this product name to the format 'Brand Model Storage'. Product name: {name}. Output in JSON form.\"}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# Standardize product names\n",
    "standardized_names = [standardize_product_name(name) for name in product_names]\n",
    "\n",
    "# Display results\n",
    "for original, standardized in zip(product_names, standardized_names):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Standardized: {clean(standardized)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample customer data\n",
    "customers = [\n",
    "    \"John Doe, 35 years old, buys electronics frequently\",\n",
    "    \"Jane Smith, 28 years old, purchases cosmetics monthly\",\n",
    "    \"Bob Johnson, 50 years old, buys gardening supplies occasionally\"\n",
    "]\n",
    "\n",
    "# Function to categorize customer\n",
    "def categorize_customer(description):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data categorization assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Categorize this customer into one of these categories: Tech Enthusiast, Beauty Lover, Home & Garden. Customer description: {description}. Output in JSON form.\"}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# Categorize customers\n",
    "categorized_customers = [categorize_customer(customer) for customer in customers]\n",
    "\n",
    "# Display results\n",
    "for customer, category in zip(customers, categorized_customers):\n",
    "    print(f\"Customer: {customer}\")\n",
    "    print(f\"Category: {category['category']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample location data\n",
    "locations = [\n",
    "    \"New York, NY\",\n",
    "    \"Los Angeles, California\",\n",
    "    \"Chicago, IL, USA\",\n",
    "    \"San Fran\"\n",
    "]\n",
    "\n",
    "# Function to normalize location data\n",
    "def normalize_location(location):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a location data normalization assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Normalize this location: {location}. Output in JSON form with city, state, and country.\"}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "# Normalize locations\n",
    "normalized_locations = [normalize_location(loc) for loc in locations]\n",
    "\n",
    "# Display results\n",
    "for original, normalized in zip(locations, normalized_locations):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Normalized: {normalized}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. References and Further Reading\n",
    "\n",
    "1. OpenAI API Documentation: https://platform.openai.com/docs/\n",
    "2. \"Natural Language Processing with Transformers\" by Lewis Tunstall, Leandro von Werra, and Thomas Wolf\n",
    "3. \"Speech and Language Processing\" by Dan Jurafsky and James H. Martin\n",
    "4. \"Text Mining with R\" by Julia Silge and David Robinson\n",
    "5. \"Applied Text Analysis with Python\" by Benjamin Bengfort, Rebecca Bilbro, and Tony Ojeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
